{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8D0LTL8fLGFnsU3lauqUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakash756/aakash-ml/blob/main/2.%20Candidate%20elimination.py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBNCDYnM6KvP",
        "outputId": "931fe46d-4f07-436c-db87-f52b25ed0e73"
      },
      "source": [
        "import copy\n",
        "def initialize_hypotheses(n):\n",
        "    hypotheses = []\n",
        "    specific_hypothesis = ['0'] * n\n",
        "    general_hypothesis = ['?'] * n\n",
        "    hypotheses.append(specific_hypothesis)\n",
        "    hypotheses.append(general_hypothesis)\n",
        "    return hypotheses\n",
        "def candidate_elimination(training_data):\n",
        "    num_attributes = len(training_data[0]) - 1\n",
        "    hypotheses = initialize_hypotheses(num_attributes)\n",
        "    for example in training_data:\n",
        "        # Handling Positive Examples\n",
        "        if example[-1] == 'Yes':\n",
        "            # Update specific hypothesis (hypotheses[0])\n",
        "            for i in range(num_attributes):\n",
        "                if hypotheses[0][i] != '0' and hypotheses[0][i] != example[i]:\n",
        "                    hypotheses[0][i] = '?'\n",
        "\n",
        "            # Rebuild general hypotheses to filter inconsistent ones for positive examples\n",
        "            current_specific_hypothesis = hypotheses[0]\n",
        "            temp_general_hypotheses = hypotheses[1:] # Get current general hypotheses\n",
        "\n",
        "            consistent_general_hypotheses = []\n",
        "            for h_gen in temp_general_hypotheses:\n",
        "                is_consistent = True\n",
        "                for k in range(num_attributes): # Check all attributes for consistency\n",
        "                    if h_gen[k] != '?' and h_gen[k] != example[k]:\n",
        "                        is_consistent = False\n",
        "                        break\n",
        "                if is_consistent:\n",
        "                    consistent_general_hypotheses.append(h_gen)\n",
        "\n",
        "            hypotheses = [current_specific_hypothesis] + consistent_general_hypotheses # Update `hypotheses` list\n",
        "\n",
        "        # Handling Negative Examples\n",
        "        else:\n",
        "            hypotheses_to_remove = []\n",
        "            hypotheses_to_add = []\n",
        "\n",
        "            current_hypotheses_copy = copy.deepcopy(hypotheses)\n",
        "\n",
        "            for h_item in current_hypotheses_copy:\n",
        "                if h_item[:-1] != example[:-1] + ['?']:\n",
        "                    hypotheses_to_remove.append(h_item)\n",
        "\n",
        "                for i in range(num_attributes):\n",
        "                    if example[i] != h_item[i] and h_item[i] != '?':\n",
        "                        new_hypothesis = copy.deepcopy(h_item)\n",
        "                        new_hypothesis[i] = '?'\n",
        "                        if new_hypothesis not in hypotheses_to_add and new_hypothesis not in hypotheses:\n",
        "                            hypotheses_to_add.append(new_hypothesis)\n",
        "\n",
        "            for h_rem in hypotheses_to_remove:\n",
        "                if h_rem in hypotheses:\n",
        "                    hypotheses.remove(h_rem)\n",
        "\n",
        "            for h_add in hypotheses_to_add:\n",
        "                if h_add not in hypotheses:\n",
        "                    hypotheses.append(h_add)\n",
        "\n",
        "    return hypotheses\n",
        "training_data = [\n",
        "    ['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes'],\n",
        "    ['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes'],\n",
        "    ['Rainy', 'Cold', 'High', 'Weak', 'Cool', 'Change', 'No'],\n",
        "    ['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n",
        "]\n",
        "result_hypotheses = candidate_elimination(training_data)\n",
        "print(\"Result Hypotheses:\")\n",
        "for h in result_hypotheses:\n",
        "    print(h)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result Hypotheses:\n",
            "['?', '0', '0', '0', '0', '0']\n"
          ]
        }
      ]
    }
  ]
}